{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "m5d6yClQ1_ib"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U requests pillow tqdm transformers ftfy regex sentence_transformers imagehash opencv-python simple_image_download google-generativeai google-cloud-secret-manager python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "bEnZWDKBwS4-",
    "outputId": "afa6329f-ee64-4435-c737-fbb23cf80f27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 images. Already processed: 279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 352/352 [03:18<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Done (or stopped due to quota). Processed metadata written to: D:\\SE_Data\\data\\ghibli\\train\\metadata.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "from tqdm import tqdm\n",
    "# load .env if present so GEMINI_API_KEY can be set there\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# =============================\n",
    "# 1. CONFIG\n",
    "# =============================\n",
    "\n",
    "# Load GEMINI API key from Secret Manager or environment (do NOT store keys directly in the notebook)\n",
    "def _get_gemini_key(project_id=None, secret_id=\"GEMINI_API_KEY\"):\n",
    "    # 1) env var\n",
    "    key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if key:\n",
    "        return key\n",
    "\n",
    "    # 2) Colab Secrets (if running in Colab and you saved a secret with name 'GEMINI_API_KEY')\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        key = userdata.get(\"GEMINI_API_KEY\")\n",
    "        if key:\n",
    "            return key\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) Google Secret Manager (requires GOOGLE_CLOUD_PROJECT or explicit project_id)\n",
    "    try:\n",
    "        from google.cloud import secretmanager\n",
    "        project_id = project_id or os.getenv(\"GOOGLE_CLOUD_PROJECT\") or os.getenv(\"GCLOUD_PROJECT\")\n",
    "        if not project_id:\n",
    "            raise RuntimeError(\"No Google project id found for Secret Manager. Set environment variable GOOGLE_CLOUD_PROJECT or pass project_id.\")\n",
    "        client = secretmanager.SecretManagerServiceClient()\n",
    "        name = f\"projects/{project_id}/secrets/{secret_id}/versions/latest\"\n",
    "        response = client.access_secret_version(request={\"name\": name})\n",
    "        return response.payload.data.decode(\"UTF-8\")\n",
    "    except Exception as e:\n",
    "        # If we couldn't retrieve from Secret Manager, raise a clear error\n",
    "        raise RuntimeError(\"Could not obtain GEMINI_API_KEY from env/Colab/Secret Manager: \" + str(e))\n",
    "\n",
    "# Retrieve key (this will raise if not found)\n",
    "# Load GEMINI API key from local .env or environment (simplified for local runs)\n",
    "# Do NOT hardcode the key in the notebook. Set GEMINI_API_KEY in d:\\SE_Data\\.env or as an env var.\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not GEMINI_API_KEY:\n",
    "    raise RuntimeError(\n",
    "    \"GEMINI_API_KEY not found. Please add GEMINI_API_KEY=your_key to d:\\SE_Data\\.env or set the environment variable before running.\"\n",
    "    )\n",
    "INPUT_FOLDER = \"D:\\\\SE_Data\\\\dataset_train\"\n",
    "OUTPUT_FOLDER = \"D:\\\\SE_Data\\\\data\\\\ghibli\\\\train\"\n",
    "METADATA_FILE = os.path.join(OUTPUT_FOLDER, \"metadata.jsonl\")\n",
    "\n",
    "# If you want to force starting over set FORCE_CLEAR_METADATA = True\n",
    "FORCE_CLEAR_METADATA = False\n",
    "RESUME = True  # if True, skip images already present in metadata.jsonl\n",
    "# Auto-wait configuration: when quota is exhausted, optionally wait and retry\n",
    "AUTO_WAIT_ON_QUOTA = True  # if True, wait then retry when ResourceExhausted is raised\n",
    "QUOTA_WAIT_SECONDS = 600  # seconds to wait between quota-check retries (default 10 minutes)\n",
    "QUOTA_MAX_RETRIES = 6  # how many wait+retry attempts before giving up\n",
    "\n",
    "# START_FROM: if your source filenames are numeric (e.g. \"281.jpg\"), this will skip any source file with index < START_FROM\n",
    "START_FROM = 281\n",
    "# Limits to protect key/quota during a long run\n",
    "MAX_API_CALLS_PER_RUN = 1000  # stop after this many successful API calls in one notebook run\n",
    "MAX_RUN_SECONDS = 60 * 60 * 4  # stop after this many seconds of wall-time (default 4 hours)\n",
    "\n",
    "CAPTION_PROMPT = \"\"\"\n",
    "You will receive an image. Describe it in a detailed Ghibli-style caption.\n",
    "Rules:\n",
    "- Start with: \"Ghibli style ...\" make sure there are no colons in the sentence.\n",
    "- Do NOT include any character names, even if recognizable.\n",
    "- Describe age, gender, facial features, eyes, nose, expression, hairstyle, and clothing.\n",
    "- Describe posture or action.\n",
    "- Describe the background environment with cinematic detail (light, mood, atmosphere).\n",
    "- Use vivid, textured adjectives.\n",
    "- Make the caption at least 30–45 words.\n",
    "- Never mention Studio Ghibli or movie titles.\n",
    "\"\"\"\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "# =============================\n",
    "# 2. PREPARE OUTPUT STRUCTURE\n",
    "# =============================\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "if FORCE_CLEAR_METADATA:\n",
    "    open(METADATA_FILE, \"w\").close()\n",
    "else:\n",
    "    # Ensure metadata file exists (but don't clear it)\n",
    "    if not os.path.exists(METADATA_FILE):\n",
    "        open(METADATA_FILE, \"w\").close()\n",
    "\n",
    "# =============================\n",
    "# 3. PROCESS IMAGES (with resume + quota handling)\n",
    "# =============================\n",
    "\n",
    "image_files = [\n",
    "    f for f in os.listdir(INPUT_FOLDER)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "]\n",
    "image_files.sort()\n",
    "\n",
    "# Load already-processed filenames from metadata so we can resume\n",
    "processed_files = set()\n",
    "if RESUME and os.path.exists(METADATA_FILE):\n",
    "    try:\n",
    "        with open(METADATA_FILE, \"r\", encoding=\"utf-8\") as mread:\n",
    "            for line in mread:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    obj = json.loads(line)\n",
    "                    # Prefer source_file (original filename). Fallback to file_name for backward compatibility.\n",
    "                    if \"source_file\" in obj:\n",
    "                        processed_files.add(obj[\"source_file\"])\n",
    "                    elif \"file_name\" in obj:\n",
    "                        processed_files.add(obj[\"file_name\"])\n",
    "                except Exception:\n",
    "                    # ignore malformed lines\n",
    "                    continue\n",
    "    except Exception as e:\n",
    "        print(\"Warning: could not read metadata file to resume:\", e)\n",
    "\n",
    "print(\"Found\", len(image_files), \"images. Already processed:\", len(processed_files))\n",
    "\n",
    "# Compute next output index based on existing output files to avoid collisions\n",
    "existing_indices = []\n",
    "for f in os.listdir(OUTPUT_FOLDER):\n",
    "    if f.lower().endswith('.jpg') and f[:-4].isdigit():\n",
    "        try:\n",
    "            existing_indices.append(int(f[:-4]))\n",
    "        except ValueError:\n",
    "            continue\n",
    "next_index = max(existing_indices) if existing_indices else 0\n",
    "\n",
    "# Open metadata for appending and keep writing one line per successful caption.\n",
    "import time\n",
    "from google.api_core import exceptions as g_exc\n",
    "\n",
    "start_time = time.time()\n",
    "api_call_count = 0\n",
    "\n",
    "with open(METADATA_FILE, \"a\", encoding=\"utf-8\") as meta:\n",
    "\n",
    "    quota_exhausted = False\n",
    "    for filename in tqdm(image_files, desc=\"Processing\"):\n",
    "        # If START_FROM set and filename is numeric, skip those < START_FROM\n",
    "        stem = os.path.splitext(filename)[0]\n",
    "        try:\n",
    "            stem_idx = int(stem)\n",
    "        except Exception:\n",
    "            stem_idx = None\n",
    "        if START_FROM and stem_idx is not None and stem_idx < START_FROM:\n",
    "            continue\n",
    "\n",
    "        # If resuming, skip already-processed images (based on metadata file entries - which prefer source_file)\n",
    "        if RESUME and filename in processed_files:\n",
    "            continue\n",
    "\n",
    "        # Stop if we've hit runtime or api call limits\n",
    "        if api_call_count >= MAX_API_CALLS_PER_RUN:\n",
    "            print(f\"Reached MAX_API_CALLS_PER_RUN={MAX_API_CALLS_PER_RUN}. Stopping.\")\n",
    "            break\n",
    "        if (time.time() - start_time) > MAX_RUN_SECONDS:\n",
    "            print(f\"Reached MAX_RUN_SECONDS={MAX_RUN_SECONDS}. Stopping.\")\n",
    "            break\n",
    "\n",
    "        input_path = os.path.join(INPUT_FOLDER, filename)\n",
    "        next_index += 1\n",
    "        output_name = f\"{next_index}.jpg\"\n",
    "        output_path = os.path.join(OUTPUT_FOLDER, output_name)\n",
    "\n",
    "        # ---- Load image ----\n",
    "        img = Image.open(input_path).convert(\"RGB\")\n",
    "\n",
    "        # ---- Save resized image into train folder ----\n",
    "        img.save(output_path, \"JPEG\", quality=95)\n",
    "\n",
    "        # ---- Ask Gemini for caption with retries/backoff ----\n",
    "        caption = None\n",
    "        max_retries = 5\n",
    "        backoff = 2  # seconds, will grow exponentially\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            try:\n",
    "                with open(output_path, \"rb\") as fimg:\n",
    "                    response = model.generate_content(\n",
    "                        [CAPTION_PROMPT, {\"mime_type\": \"image/jpeg\", \"data\": fimg.read()}],\n",
    "                        safety_settings={\"HARASSMENT\": \"BLOCK_NONE\"},\n",
    "                    )\n",
    "                caption = response.text.strip()\n",
    "                api_call_count += 1\n",
    "                break  # success\n",
    "            except g_exc.ResourceExhausted as e:\n",
    "                # API quota exhausted for the project/account.\n",
    "                if AUTO_WAIT_ON_QUOTA:\n",
    "                    print(\"ResourceExhausted (quota). Will wait and retry according to QUOTA_WAIT_SECONDS / QUOTA_MAX_RETRIES.\")\n",
    "                    quota_retry = 0\n",
    "                    caption = None\n",
    "                    while quota_retry < QUOTA_MAX_RETRIES:\n",
    "                        quota_retry += 1\n",
    "                        print(f\"Waiting {QUOTA_WAIT_SECONDS} seconds before retry attempt {quota_retry}/{QUOTA_MAX_RETRIES}...\")\n",
    "                        time.sleep(QUOTA_WAIT_SECONDS)\n",
    "                        try:\n",
    "                            with open(output_path, \"rb\") as fimg:\n",
    "                                response = model.generate_content(\n",
    "                                    [CAPTION_PROMPT, {\"mime_type\": \"image/jpeg\", \"data\": fimg.read()}],\n",
    "                                    safety_settings={\"HARASSMENT\": \"BLOCK_NONE\"},\n",
    "                                )\n",
    "                            caption = response.text.strip()\n",
    "                            api_call_count += 1\n",
    "                            print(\"Succeeded after waiting. Continuing processing.\")\n",
    "                            break\n",
    "                        except g_exc.ResourceExhausted:\n",
    "                            print(f\"Still ResourceExhausted after wait attempt {quota_retry}.\")\n",
    "                            continue\n",
    "                        except Exception as e2:\n",
    "                            # other transient error while retrying after wait; fall back to outer retry logic\n",
    "                            print(f\"Error when retrying after wait: {e2}. Will continue with retry/backoff.\")\n",
    "                            break\n",
    "\n",
    "                    if caption is not None:\n",
    "                        # success after waiting, proceed to save caption\n",
    "                        pass\n",
    "                    else:\n",
    "                        print(\"Quota still exhausted after configured retries. Stopping further processing. Processed results are saved.\")\n",
    "                        quota_exhausted = True\n",
    "                        break\n",
    "                else:\n",
    "                    print(\"ResourceExhausted (quota). Stopping further requests. Processed results are saved.\")\n",
    "                    quota_exhausted = True\n",
    "                    break\n",
    "            except g_exc.InternalServerError as e:\n",
    "                # server side error, retry\n",
    "                print(f\"InternalServerError on attempt {attempt}: {e}. Retrying after {backoff} s...\")\n",
    "            except g_exc.ServiceUnavailable as e:\n",
    "                print(f\"ServiceUnavailable on attempt {attempt}: {e}. Retrying after {backoff} s...\")\n",
    "            except Exception as e:\n",
    "                # Generic exception (network, timeouts, rate limits). Retry a few times before giving up\n",
    "                print(f\"Error on attempt {attempt}: {e}. Retrying after {backoff} s...\")\n",
    "\n",
    "            # backoff before next retry (unless we're on last attempt)\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(backoff)\n",
    "                backoff *= 2\n",
    "\n",
    "        if quota_exhausted:\n",
    "            # Stop processing more images; keep everything written so far\n",
    "            break\n",
    "\n",
    "        if caption is None:\n",
    "            # Could not produce a caption after retries. Save an entry indicating failure so we don't keep retrying forever.\n",
    "            print(f\"Failed to generate caption for {filename} after {max_retries} attempts. Saving placeholder and continuing.\")\n",
    "            caption = \"[ERROR: failed to generate caption]\"\n",
    "\n",
    "        # ---- Save metadata ----\n",
    "        entry = {\"file_name\": output_name, \"text\": caption}\n",
    "        meta.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "        meta.flush()\n",
    "        try:\n",
    "            os.fsync(meta.fileno())\n",
    "        except Exception:\n",
    "            # fsync may not be available on all systems; ignore if it fails\n",
    "            pass\n",
    "\n",
    "print(\"✔ Done (or stopped due to quota). Processed metadata written to:\", METADATA_FILE)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
